{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "KNGPT-2simple",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tegee/gpt-2/blob/master/KNGPT_2simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28552ecf-8424-487f-fc40-eee2688732ea"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"345M\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 627Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 101Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 261Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:08, 166Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 522Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 106Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 184Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBoBPlEwxDyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc3b205b-57b1-48e3-97eb-55419428abd8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"/content/drive/MyDrive/KafiNnoonoo_corpus_for_vocab.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hhYf_VE30DM"
      },
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS"
      },
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km_hXKNvYpJm"
      },
      "source": [
        " %logstart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeXshJM-Cuaf",
        "outputId": "ed8478ae-2d86-4af8-faa3-9dbb71b6de25"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='345M',\n",
        "              steps=1500,\n",
        "              restore_from='fresh',\n",
        "              run_name='KNGPT2P',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500,\n",
        "              )\n",
        "              "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
            "Instructions for updating:\n",
            "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
            "Loading checkpoint models/345M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/345M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:04<00:00,  4.29s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 1106968 tokens\n",
            "Training...\n",
            "[10 | 24.08] loss=4.19 avg=4.19\n",
            "[20 | 39.48] loss=3.00 avg=3.59\n",
            "[30 | 55.10] loss=3.47 avg=3.55\n",
            "[40 | 70.95] loss=2.52 avg=3.29\n",
            "[50 | 87.10] loss=3.07 avg=3.24\n",
            "[60 | 103.49] loss=2.91 avg=3.19\n",
            "[70 | 120.17] loss=2.53 avg=3.09\n",
            "[80 | 137.32] loss=2.90 avg=3.06\n",
            "[90 | 154.53] loss=3.99 avg=3.17\n",
            "[100 | 171.54] loss=2.24 avg=3.07\n",
            "[110 | 188.42] loss=2.40 avg=3.01\n",
            "[120 | 205.40] loss=2.64 avg=2.98\n",
            "[130 | 222.47] loss=2.48 avg=2.94\n",
            "[140 | 239.56] loss=2.10 avg=2.87\n",
            "[150 | 256.62] loss=2.79 avg=2.87\n",
            "[160 | 273.68] loss=2.32 avg=2.83\n",
            "[170 | 290.79] loss=2.42 avg=2.81\n",
            "[180 | 307.87] loss=2.00 avg=2.76\n",
            "[190 | 324.98] loss=2.59 avg=2.75\n",
            "[200 | 342.02] loss=2.15 avg=2.71\n",
            "======== SAMPLE 1 ========\n",
            "kq echehe aroochee maweetoo qaaroona beetoon moorxi gaboona qaaroona beetogaata qaarii beeto bi qaaroona kexoochoomon, biin gaboona qaaroona beeto qaarus tachoo ikonoyich bi nihoo ikka niyoo ikka gaboona qaaroona beetogaata qaarahoo birigiti shaweexi beeto aaareena' och kooreetina' och qaaroona tochaabeeton qaarakibaroon ikka qaaroona beetoo qaaroona beetonaa qaaro bi ciinnineto shunnit ikka bi qaaree maweetoyich qaarii beeto bi qaaroona qannaa beeto biichoo qaaro qaaro qaaro qaaroona beeto qaarus tachoo biin gaboona qaaro taatittinee qaaroona beeto biinaa beetogaata biin bi qaaree shittoon ta qaareena' o ikkka qaareena' o ikka quyaano bi qaaroona qannaa beetonaa qaaro bi kofaaree bi qaarii beeto qaare xejje qaare qaare qaare qaarei qaareena' o qaare qaare qaareena' o aroo qaareena' o qaare qaare qaareena' o qaare qaareena' o koniyoo qaaroona beetoo qaaroona beetee qaaroona beetonaa qaaroona beetonee qaareena' ona boono taane beetonee qaare Qaarea' oq wochiq wochiq biin qaareena' o qaaro bee qaaroona beeto Qaaroonaa daqqoona arii beeto qaaro qaaro qaaro qaaro kechi keeja hinnooch bedahee kechi qaaro qaaroona beetone<|eos|>.<|eos|>.<|eos|>Eeceq echee qaareena' o ikka quyaano bi quaaroona qaaroona qaaroona qaarboona qaaroon arii beeto Qaaroonaa daqqoona ariche yibbaatahebi kooroo wochiq qaaroona naxhee xibiyooch wochibare Qaaroonaa ta gidiyooch wochibare eche qaareena' ochi quanna kaatooch biriibare bi ta giddibaroona qaaroona qaaroona qaarrit qaaro qaaroona quaaroona ebi shimoo qaaro qaaro qaaroona qaaro qaaro qaaroona qaarrit eche qaareena' o ta waan waani Qaaroonaa ta biriibare Qaaroonaa ta ikka qaaroona qaaroona qaaro qaaro qaaroona qaaro qaaroona qaarrit echee qaareena' o ta yiirichi Qaaroonaa ta qaaroona qaaroona qaaroona Qaaroonaa kaatooch biriibare Qaaroonaa qaaroonoo qaaroonaa ciinniq qaaroona qaaroonaa kaatooch bi waan quaaroona qaaroonaa qaaroonaa qaaroonaa qaaroonaa qaaro Qaaroona Qaaroonaa qaaroonaa Qaaroonaa waanee qaaroona waahooba qaaroonaa waayataani quachoonaa ikka kimoo qaaro qaare qaaroona ikka qaare qaare qaaroona Qaaroonaa qaaroonaa qaaroonaa qaaroonaa hinihe qaaroona ikka hinihe qaaroona qaare h\n",
            "\n",
            "[210 | 384.40] loss=2.17 avg=2.69\n",
            "[220 | 401.51] loss=2.42 avg=2.67\n",
            "[230 | 418.74] loss=2.28 avg=2.65\n",
            "[240 | 435.99] loss=1.76 avg=2.61\n",
            "[250 | 453.24] loss=2.48 avg=2.61\n",
            "[260 | 470.46] loss=2.35 avg=2.59\n",
            "[270 | 487.69] loss=2.33 avg=2.58\n",
            "[280 | 504.87] loss=2.13 avg=2.56\n",
            "[290 | 522.08] loss=2.28 avg=2.55\n",
            "[300 | 539.30] loss=2.48 avg=2.55\n",
            "[310 | 556.49] loss=2.54 avg=2.55\n",
            "[320 | 573.65] loss=2.12 avg=2.53\n",
            "[330 | 590.84] loss=1.90 avg=2.51\n",
            "[340 | 608.03] loss=2.17 avg=2.50\n",
            "[350 | 625.26] loss=2.06 avg=2.49\n",
            "[360 | 642.45] loss=2.47 avg=2.49\n",
            "[370 | 659.67] loss=2.12 avg=2.47\n",
            "[380 | 676.88] loss=2.20 avg=2.46\n",
            "[390 | 694.08] loss=1.78 avg=2.44\n",
            "[400 | 711.30] loss=1.75 avg=2.42\n",
            "======== SAMPLE 1 ========\n",
            "ar>  ikke phiroona xuhoon ariyaanoona biin koorito gaacheyoon yechitina' o beeti xuhoona wochoon biiyatina' o wuxiteemi maacheye<|eos|>. <|sos|> gondooch bi dukkeemm koorito sheqqoona biich koorito gaacheyoon tiiyoon gaacheyoona biiyati naa koorito gaacheyoon xefee kooritogaata danemmo gaacechone; bi qelloon aaf beshoon tiiyoo, yechito gaacheyaaboo biich beeto gaacheyyin yechiti amee qaaroon bi ciichitoyich ta doono yesuus kiristoosichi birete maacooch kette gondoon maaco gaacheyoon danemmo gaacechone; bi qelloon aaf beshoon tiiyoo, ikke maaco gaacheyoon birete sheqqoona biich beeto gondoona daakkeena' oyich qannayemm shalligoon ebin shalligito gaacheyoon digeno taane<|eos|>. <|sos|> aadabboon sheqqoona bi daachittine maakko gaacheyoyich xefee shaaheena' on kaachi sheqqo qajemmo gaata wochoona shuuniibeeti qoodoon ebin danetina' one; bireena' oyich qifireena' oyich qannayemmo bi tunoon xemona arii beeto gaacheyiyeete<|eos|>. <|sos|> hariyoonaa bireena' oyich qifireena' oyich bireena' shaaheena' ochi qoodoon gaacheyoon digeno taane; bireena' on biich sheqqo gaacheheete<|eos|>. <|sos|> biyoo biich beeti hariyaa andire kaachi shaaheena' on kaachoone<|eos|>. <|sos|> biyoo ebiyoo, gaacheyee taatooch doono yesuus giixiti ashi shaahoon kaacho gaacheyoon digeno taane<|eos|>. <|sos|> ebine maaceexi maayoon hallittine qihoon ikke maacooch bi yechitoyichiye; asho gaawe ikke shaahee bi dabbeena' oyich bi cimmona hiniich beeti mooyo gondoon iriti ibaroon sheqqo gaacheyochi gaacciye; aro bi qoppeqimon iritiyalli, kaate ta ikke taan bi dabbeena' oyich qelloon biiyachi shaache<|eos|>. <|sos|> bireena' oyich qelloon biiyemmoch xibriiti shalligoon ebin ciireebeeto gaata aabichii bi kooriti wocoon danemmina' one; ebibote! iye<|eos|>. <|sos|> gondoon dabbiichii gondoonaa gondoon doono yesuus kiristoosichi birete shiisheena' o qihee kottoona cadiqii beeto gaata maabichiqqi dabbite! iye<|eos|>. <|sos|> maacho gaacheyee maabichiqqi gondoon qelli shiche shichito kiristoosichi bireena' o koorito gaacheyoo biich qihoon koorito gondoon diciyolla biin wochiye; biyoo maachet kooreeti mooyolla wochiichoo biich qelli qecoon biiyemmi aamoona tiiyemmoch gondoonaa wotta bi shuxxo bi tunoon diciyittine shaaheena' oyich kaarech ta ciichitoyich, bireena' oyich shalligoon gaacheyaanoon shuunaheete<|eos|>. <|sos|> bireena' oyich qifireena' o hiniyee daneemmo woganin qannayaa gondoon doono qelli\n",
            "\n",
            "[410 | 751.11] loss=2.13 avg=2.41\n",
            "[420 | 768.20] loss=2.03 avg=2.40\n",
            "[430 | 785.41] loss=3.26 avg=2.43\n",
            "[440 | 802.72] loss=1.67 avg=2.41\n",
            "[450 | 819.91] loss=1.98 avg=2.39\n",
            "[460 | 837.03] loss=2.06 avg=2.39\n",
            "[470 | 854.20] loss=1.92 avg=2.37\n",
            "[480 | 871.32] loss=2.25 avg=2.37\n",
            "[490 | 888.45] loss=2.15 avg=2.36\n",
            "[500 | 905.65] loss=1.90 avg=2.35\n",
            "Saving checkpoint/KNGPT2P/model-500\n",
            "[510 | 930.59] loss=2.08 avg=2.35\n",
            "[520 | 948.24] loss=2.13 avg=2.34\n",
            "[530 | 965.52] loss=2.18 avg=2.34\n",
            "[540 | 982.56] loss=1.75 avg=2.32\n",
            "[550 | 999.69] loss=1.85 avg=2.31\n",
            "[560 | 1016.89] loss=1.96 avg=2.30\n",
            "[570 | 1034.08] loss=1.97 avg=2.30\n",
            "[580 | 1051.39] loss=2.45 avg=2.30\n",
            "[590 | 1068.66] loss=2.01 avg=2.29\n",
            "[600 | 1085.88] loss=2.21 avg=2.29\n",
            "======== SAMPLE 1 ========\n",
            " o<|sos|> dukkii kichii<|eos|>.<|sos|> makashee xibiyee, oogii gaata, gaatee qanna, gaawatonooch kichaa, gaatinee shambatee, gaawaton bi kechette<|eos|>.<|sos|> gaata, wochaabee, uumiyoona, ayibashee, ikkikka mooyona, dab<|eos|>.<|sos|> shambatee shimbo, shamaani, waaraachoochiye ittoshi shunniti oohee kimooch beeti oohee xibittino ikkooch aacocha ikkinne gaata, gaawaton bi qellich gaata, miixaa bekkii gaata, kuxiyaahotine! iye<|eos|>.<|sos|> qorontoosi qorontoosi ebin dabbii beetina' on aabichireete<|eos|>.<|sos|> aacha iritooba, kaacheti iritoon iberichi bushoo biin xibittino toonoone<|eos|>.<|sos|> shaddeyaache<|eos|>.<|sos|> amoone? iqqi echaheete<|eos|>.<|sos|> shaddeyaache<|eos|>.<|sos|> amoone? iqqi echaheete<|eos|>.<|sos|> ikka yemeenee xibittino ikkinochi ikka uro, aachi uro, gaawa yechii uro<|eos|>.<|sos|> giishacha wodde gaawa gaxxee beetone<|eos|>.<|sos|> wodde gaara shaweexi oohee wodde gaawa gaxxee beetone; ginee naayo wodde gaara yechii uroon aafichii qanniyona? iye<|eos|>.<|sos|> wodde gaara yechii uroon aafichii qanniye qanniyona? iqqi echaheete<|eos|>.<|sos|> qorontoosi wodde gaara yechii uroon boono gaxxii beeto<|eos|>.<|sos|> gaawaton biich beeti gaata ukkemmone iye<|eos|>.<|sos|> gaawaton waayaqqi echaheete<|eos|>.<|sos|> ukkureena' ochi daggoochee ikke ukkureena' ochi daggoochee ikke qocoon qechii beeto ikke ukkureena' ochi daggoochee ikke makashee aagateena' on tiqqaa ikke daakkoon sheqqeebe<|eos|>.<|sos|> iqqi echaheete<|eos|>.<|sos|> illa sheqqeeti sheqqeena' onaa boono beegoonon iqqi bi qoodiqqa ukkeehe<|eos|>.<|sos|> xaqqaa iqqa sheqqeena' ochi ukkiyeete<|eos|>.<|sos|> ukkureena' ochi daggoochee ikkoone ebiyee aaf giixxaani kooreena' onaa doyee ukkureena' ona tookkii bi sheejinnee iritooch beeti aachi aachi uro, bi kishoochee ikke makashee ukaashoochi yibbaataache<|eos|>.<|sos|> bi sheqqo biich beeti uro, maddii bi qoodeeti gaacaache<|eos|>.<|sos|> aroochee sheddiqoona ikke ukkiiyoochi sheqqeeti sheqqeena' on xefee malleteena' oyich yibbaatoon biich qaawii beeto<|eos|>.<|sos|> shekkoon ukkureena' on\n",
            "\n",
            "[610 | 1125.59] loss=2.34 avg=2.29\n",
            "[620 | 1142.69] loss=2.11 avg=2.29\n",
            "[630 | 1159.89] loss=2.11 avg=2.28\n",
            "[640 | 1177.17] loss=1.60 avg=2.27\n",
            "[650 | 1194.42] loss=2.06 avg=2.27\n",
            "[660 | 1211.67] loss=1.88 avg=2.26\n",
            "[670 | 1228.83] loss=1.28 avg=2.24\n",
            "[680 | 1245.96] loss=1.82 avg=2.23\n",
            "[690 | 1263.11] loss=1.73 avg=2.22\n",
            "[700 | 1280.27] loss=1.67 avg=2.21\n",
            "[710 | 1297.43] loss=2.00 avg=2.20\n",
            "[720 | 1314.62] loss=1.92 avg=2.20\n",
            "[730 | 1331.86] loss=2.78 avg=2.21\n",
            "[740 | 1349.10] loss=2.61 avg=2.22\n",
            "[750 | 1366.36] loss=2.03 avg=2.21\n",
            "[760 | 1383.62] loss=1.75 avg=2.20\n",
            "[770 | 1400.87] loss=1.71 avg=2.20\n",
            "[780 | 1418.09] loss=1.67 avg=2.19\n",
            "[790 | 1435.27] loss=2.55 avg=2.19\n",
            "[800 | 1452.43] loss=1.77 avg=2.19\n",
            "======== SAMPLE 1 ========\n",
            " meetoshi beeto, gaayahee iqqi doonone iqqi boonoshin wochii beeto iqqi boonoshin kichi iyeete iqqi boonoshin shiichiqqa boonoshina iqqi boonoshich maddii beeto ittoshine; boonoshiyoo boonoshin ariibote! arootamoochee ittoshiho shuunaa beetoone iqqi boonoshin wocha waa beetone; areena' ona boonoshi tuniiyemmo ittoshine<|eos|>. <|sos|> boonoshiyoo ta shiijati xaa' ooch wotta ittoshin gaachehofer ittoshi iitoochee tiijiqqi boonoshich gettitone<|eos|>. <|sos|> boonoshiyoo taan woyinee wochoon boonoshi aafoon beeggito taane iye<|eos|>. <|sos|> boonoshiyoo ashi bushoo boonoshi toommooch oogee yiiyooba and hini taach beeti asho, boonoshi qelloon ariitoyee gub bi nihoon waa iqqi, qaabbaache iqqi bi iiroona boonoshi iitoochee tiijiqqi boonoshin boonoshich bi ii beeto ittoshine<|eos|>. <|sos|> boonoshiyoo bulli wochiqqaqqi bi kashoon boonoshich kotiitoyee gub taatee iye<|eos|>. <|sos|> ishi beeto ittoshine; ishi katinni yaafito boonoshine iye<|eos|>. <|sos|> boonoshiyoo taach wochoon boonoshi iyaachemmoyich, boonoshi tahoo xaa' ooch beeti iqqi am shaaha boonoshin boonoshi iyaachemmoyich boonoshi iyaachemmoyich boonoshi iyaachemmoyich boonoshi iyaachemmoyich boonoshi iyaachemmoyich boonoshi iyaachemmoyich boonoshi iyaachemmoyich boonoshi iyaachemmoyich boonoshi iyaachemmoyich boonoshi iyaachemmoyich boonoshi iyaachemmoyich yeer waanee boonoshin iibbi qaaro boonoshi iyaachemmoyich, andoo boonoshich wochii beeto ittoshine<|eos|>. <|sos|> and doono yeeri taach cabbaachaa shawoona xeeyoo boonoshin boonoshich boonoshin boonoshich boonoshi iyaachemmoyich, and wochinnoon boonoshi kashoon boonoshi iyaachemmoyich boonoshi iyaachemmoyich boonoshi iyaachemmoyich boonoshi iyaachemmoyich boonoshi iyaachemmoyich boonoshi iyaachemmoyich boonoshi iyaachemmoyich boonoshi iyaachemmoyich boonoshi iyaachemmoyich boonoshi iyaaachemmoyich boonoshi iyaaachemmoyich, and boonoshich wochinnoon boonoshich boonoshich wochinnoon wochinnoon boonoshin iyii beeto taane iqqi wocha iqqi bi iiroona boonoshi xeeyoo boonoshine iye<|eos|>. <|sos|> aroyee shiijaroo kexooch giqqahee, amaatere ta kichemmi daqqoon dabboona, ebi geto amaatere bekkiihe? boonoshi gettiti qaaro shiichiqqi, ebi ariyoon boonoshich immone iqqi boonoshin qollaa beeto taane iqqi wocha iqqi bi iiroona boonoshi aafoochee tiijiqqa boonoshin bi shaaha gaata, boonoshin bi yulloon bekkiitoyee gub xaa' oon boonoshi iyaaachemmoyich boonoshi iyaaachemmoyich boonoshi iyaachemmoyich boonoshi iyaaachemmoyich boonoshi iyaaachemmoyich boonoshi iyaaallee beebiyoo qaabbachina quyaaa beetina' o boonoshine iqqi boonoshin qollaa beetina' O keqqoonaa boonoshi waan gaachato, boon\n",
            "\n",
            "[810 | 1492.05] loss=1.59 avg=2.17\n",
            "[820 | 1509.21] loss=1.64 avg=2.16\n",
            "[830 | 1526.44] loss=1.53 avg=2.15\n",
            "[840 | 1543.74] loss=1.80 avg=2.15\n",
            "[850 | 1561.00] loss=2.08 avg=2.15\n",
            "[860 | 1578.19] loss=1.60 avg=2.14\n",
            "[870 | 1595.41] loss=2.35 avg=2.14\n",
            "[880 | 1612.57] loss=1.52 avg=2.13\n",
            "[890 | 1629.74] loss=2.09 avg=2.13\n",
            "[900 | 1646.93] loss=2.08 avg=2.13\n",
            "[910 | 1664.08] loss=1.46 avg=2.12\n",
            "[920 | 1681.25] loss=1.97 avg=2.11\n",
            "[930 | 1698.48] loss=1.89 avg=2.11\n",
            "[940 | 1715.71] loss=1.95 avg=2.11\n",
            "[950 | 1732.95] loss=1.59 avg=2.10\n",
            "[960 | 1750.18] loss=1.87 avg=2.10\n",
            "[970 | 1767.41] loss=1.27 avg=2.08\n",
            "[980 | 1784.70] loss=1.79 avg=2.08\n",
            "[990 | 1801.97] loss=1.31 avg=2.07\n",
            "[1000 | 1819.16] loss=1.48 avg=2.06\n",
            "Saving checkpoint/KNGPT2P/model-1000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "======== SAMPLE 1 ========\n",
            " ii qaareena' o ikke wochaa shaaggitoyee gubbechi naa phelaaxoosinaa phiree sheefoonaa qoppeeti shuunoonon bekkiibot; wochinnoona shuunee woco, qamine, qamine, qamine, qamine, qamine ikkoo eboommon ikke phiree woyee shuunee bekkiibot; qamine, qaminoochee ikke phiree shuunee bekkiibot; epphee ikkoo ikke phiree ikke michoo tochech phiraabileexi mooyo ame woyee baach phire daakkoon daneyaanooyich phire gabeena' on boono phiraaboshoone? iye<|eos|>. <|sos|> tunaballi phiree phiree ta niho phire bekkoon daneyaanooyich wochinnoo dane eene<|eos|>. <|sos|> phire iritoon kichi bekkihe; dabbiibeeti kaame eeneena' o boono phire eeneena' o beeteete! iye<|eos|>. <|sos|> phiree phiree boono phire toommooch boono dane gaata ta niho phire toommooch boono qannayee phire daakko bi qannayee phire gabeena' o daneyaanoone<|eos|>. <|sos|> phiree phire ta niho phire bekkooch phire toommooch phire ta niho phire phiraabosho beegoyich phire ta niho bekkiibeegoora phire ta niho tayiichi hinneena' o beeteete<|eos|>. <|sos|> phiree ciiro phiree ciiro phire ciiro phire toommooch hinnoone; phire daakkoone; ebi phire toommooch phiraa bosho phire toommooch hinneena' o beeteete<|eos|>. <|sos|> phiree ta niho phire toommooch phiinee ciiro phire xaa' oochaa beete<|eos|>. <|sos|> phiree ta niho phiree ciiro phire daakko beete<|eos|>. <|sos|> phiree ta niho phixxee' o beeteete; ebi phiree gashooch beeti ikkoo phiraabeetone; phiraabeeti ta niho phiree qocoo phixxee' o beeteete iqqis qoco, phireena' o getaa beeteete; phiree qocoo phixxee' o beeteete iye<|eos|>. <|sos|> phiree qaareena' o phiree gashoyich beddaahee wotte' aaheena' o tocheena' o boono phiraaboshoone; phiree gashooch beeti niho phiraaboshoo phire qaareena' o beeteete; phiree gashoochee phire eeppoo phiree gashoon degoch ee' o beeteete iye<|eos|>. <|sos|> phiree gashooch beeti ciiro phire kishoona ixxee' o hiniyee deshe qero phiree gashoon kichii boono kichibot; phiree tate ciiroon gaacho qaawiye; phiree gashoon kichii boono kichii beetoone; phiree gashooch qoodeebeetoone<|eos|>. <|sos|> phiree ciirooch phiree gashooch phire gaaco hakkiye iye<|eos|>. <|sos|> ebi ikke phiree gashoon degochi gaacho hakkehe<|eos|>. <|sos|> phire qeppeena' o phiree gashooch\n",
            "\n",
            "[1010 | 1866.68] loss=1.81 avg=2.05\n",
            "[1020 | 1883.85] loss=2.16 avg=2.05\n",
            "[1030 | 1900.98] loss=1.83 avg=2.05\n",
            "[1040 | 1918.19] loss=1.54 avg=2.04\n",
            "[1050 | 1935.49] loss=2.17 avg=2.05\n",
            "[1060 | 1952.77] loss=1.83 avg=2.04\n",
            "[1070 | 1970.00] loss=1.62 avg=2.04\n",
            "[1080 | 1987.27] loss=1.76 avg=2.03\n",
            "[1090 | 2004.54] loss=1.90 avg=2.03\n",
            "[1100 | 2021.82] loss=1.99 avg=2.03\n",
            "[1110 | 2039.04] loss=1.29 avg=2.02\n",
            "[1120 | 2056.21] loss=1.13 avg=2.00\n",
            "[1130 | 2073.44] loss=1.44 avg=2.00\n",
            "[1140 | 2090.77] loss=1.71 avg=1.99\n",
            "[1150 | 2108.00] loss=1.75 avg=1.99\n",
            "[1160 | 2125.19] loss=2.01 avg=1.99\n",
            "[1170 | 2142.34] loss=1.37 avg=1.98\n",
            "[1180 | 2159.57] loss=1.53 avg=1.97\n",
            "[1190 | 2176.86] loss=2.21 avg=1.98\n",
            "[1200 | 2194.08] loss=2.00 avg=1.98\n",
            "======== SAMPLE 1 ========\n",
            "a tiyoorina miheena' ooch, bi kechi asheena' onaa mihe kocoona tookkii dojii beeti ikkittinoona ebi mihe daqqoona tunati mihe xaa' ooch xumma bahareebeeti inde shuunoonaa dege shuuneena' onochi shuunoona tookkii shemmechon tuniihe shemme daniyoonaa giddeebeeyaani mihe shaaheena' ona tookkii, shalligee daqqo ittoshi, yesuus kiristoosina tookkii baribare kitaamitoochaa ittoshi gofino shaahiyeena' on ciinniyeete dambee tochiya beddimmi shuraaro kitaamitoochaa ittoshi toociyeemmoch kiciyoo tuneba guuphi shuunoonaa kooree xuureena' ona toocoona hamaa dabboona kitaamitoochaa tuneba mihe shaaheena' onaa mihee kocoona xaa' ooch giddeteete guuphiyoo tunaqqi wochee toociyee doyoo boono ga' ooch aametee, wochee toociyechina' oona shacona, ga' oochaa kitaamito waanee qaaweyaacheemmo tuniihe doyichoo mihe shaaheena' o gaaco daamito eke bushiisheena' o shemmeegoora woddii doyee kaac cuchitone ebichi daacoon biriibote! doyechina' o kaacheheete ebich, bushiishee no eennemmogaata ittoshich beeto ciichaa no beddemmi gaata, ga' oochoo hakkiyeete wodde dego, qiddeena' one no, shemmeemm, ittoshi doyit mihe shaaheena' o daafo hakkiyeete ittoshi  kooriyaa no kotiimmona ittoshi dojjiyeemmon tuniiha itone ebich ittoshin gaawuchaa ittoshi miixeeteemmon tuniibote! yawoonaa bi ga' ooch neexaachaa dabboona kexon guuphi shuunooch heechiibee, bi daachiiti doyee yawoonaa bi ga' on gaacceemm shuunoona ittoshich arichiiyemmogaata ittoshi kotiimmona ittoshin gaawuchaa ittoshich arichiiyemmon tuniyoo ittoshich qaawiibech! mihe shaaheena' on gaacheyaani mihe toocoone; baribare gommone ittoshi amoommiyone ebi shuunooch beeti mooyon mihe toocoona, ittoshi qelloona no miitoyee gubb, baribare ebi shuuneemmi mihe toocoona ittoshi deqqemmon ariibe! ittoshi shuuneemm shaashaakka sahariito ittoshine ii beeti shuunoocho! ittoshi shuuneemmi asheena' on tatoona nallachina' ona kitaamiteete ittoshi kaalloochaa ittoshi shuuneton wochi dambeebeeti asheena' oochee ikkoo doyechina' o bushiisheena' on biriibeetona ittoshich getaani ukaa beetona, biriibot no immooch giyiyee buura kishee gaaco aaconon mihe toocoona tuniihe; shaashaakka saaremmo noona, no nallaa doyoonaa baribare gommi kishee gaacooch bi giddiyeemmoch tunato noone; ebi kishee gaboo nooch giddeemmi kishee gaboo nooch giddeemmi kishee gaboo nooch giddeemmi kishee gaboonoo baribare bi goyoochee tiishoochee tiishoon digenooyich bede; biriibot no immooch giyiyee buura\n",
            "\n",
            "[1210 | 2233.10] loss=1.55 avg=1.97\n",
            "[1220 | 2250.31] loss=1.17 avg=1.96\n",
            "[1230 | 2267.54] loss=1.65 avg=1.96\n",
            "[1240 | 2284.78] loss=1.64 avg=1.95\n",
            "[1250 | 2302.09] loss=1.50 avg=1.94\n",
            "[1260 | 2319.34] loss=1.59 avg=1.94\n",
            "[1270 | 2336.55] loss=1.59 avg=1.93\n",
            "[1280 | 2353.72] loss=1.50 avg=1.93\n",
            "[1290 | 2370.93] loss=1.48 avg=1.92\n",
            "[1300 | 2388.11] loss=2.03 avg=1.92\n",
            "[1310 | 2405.25] loss=1.61 avg=1.92\n",
            "[1320 | 2422.45] loss=2.31 avg=1.92\n",
            "[1330 | 2439.75] loss=1.65 avg=1.92\n",
            "[1340 | 2457.00] loss=1.35 avg=1.91\n",
            "[1350 | 2474.18] loss=1.41 avg=1.91\n",
            "[1360 | 2491.27] loss=0.93 avg=1.89\n",
            "[1370 | 2508.52] loss=1.84 avg=1.89\n",
            "[1380 | 2525.85] loss=1.28 avg=1.88\n",
            "[1390 | 2543.08] loss=2.29 avg=1.89\n",
            "[1400 | 2560.20] loss=1.83 avg=1.89\n",
            "======== SAMPLE 1 ========\n",
            "ency tochechina' on boono kooriibeet toocoon hallooch hakkiimm gaawe yaweena' on hiniichaa aroochee shafiroo qaawiihe shaahiyooch deggimm tooco hiniyee dicci shaahiyoochee kemee bekkiyechina' on iibbii shiichii shiichii shiichi shaahoon ceechii shiichii bekkiyechina' on imo tuniibeetina' och shiichi shaahoon doyimmi shuriyeena' on kicii doyoona tuno shiichii arooch deggiye shiichi shaahoon ariyechina' on boono giixxiti doyoon boono doyoona digenee kotiiho, doyiteete, dab kitaamito halliichii bushiishoon dabbiyoon immiye doyechina' och dojjechina' ot bushiishooch deggiye kette woyee maac woddittino amo tune tooco tuneba ariit shooddee iberoona boono qelli baribare doyo gaawe qiiceena' ona tunareena' on boono qelli qelloon uumiyoon kichoo hakkiyeete aribare shuuraareena' o shimbo kiiraakiireena' o kicheena' on woyee shuuneheete ebi minnakanneena' o gaaco hakkimm wotte koce shimboona yeshet wodde koceena' on digenooyich bire digene dojjoon boono qelli qelloon digeniyoo hakkeehe tate woyee yawoon mashaamit shemmoonaa minnakanneena' on yechit woyee yawo shemmoon qoppo tunegaata qaawiihe, goomii shemmeegooroon wochiwochii herechiyoona boonoshin ceeggimmo tunoon shiichii aroochee bire digene doyoon beddaaha ciinehe ebichi hinnoochaa dojjechino hiniyee bire digene yaweena' on bushiishoon yeshehe shemmo woyee kiiraakiiro qaaroon xiishiihe shemmo woyee wochiwochii herecho bi qelloona yeshiye ebi qelloochaa gaawe qiheena' o hiniyee dabbimm kiiraakiiro dojjechino qaaroon tatoona tate iiqqoon uumiye shemmeegooroon dojjee yaweena' on dojjii gaacho qaawiihe bushiisheena' ochi doyee goora shiitina' on dojjii xiishii dojjich deggiye ebichi hinnoona boono qaaroon tatoona bire digene dojjee yaweena' o boono qajjit qiheena' on boono kiciyo hin kaalloon beddaaha shunniyoon qaawiihe tunebaani shaahe kicee yaweena' on shuunehe dojjooch wodde doyechina' och bekkiyechona kaalli yaweena' on boono shigo woddittino bire digene dojjee shuuraareena' o shimboona yeshetona dege mashaamimm doyee daqqanaa doyee qayee yaweena' on tatoona boono kiciyoon qaawiihe shaahiyooch bekkiyechon wodde miheena' on imo tunoon immiibeet yawillee shemmeegooroon dojjee goora wutte yaweena' o giddeheete doyechina' o shiichii shemmeeshee yawo shemmee yawo baribare shimboon woyee mashaamimm doyechon shiichii bushichii qaawiibeet koorooch shaggege shiichii dojjibot dojjechinote wodde doyoo wodde doyoo koorooch shagga bi beet doyich mihe\n",
            "\n",
            "[1410 | 2599.09] loss=1.36 avg=1.88\n",
            "[1420 | 2616.29] loss=0.90 avg=1.87\n",
            "[1430 | 2633.51] loss=1.17 avg=1.86\n",
            "[1440 | 2650.79] loss=2.17 avg=1.86\n",
            "[1450 | 2668.06] loss=2.16 avg=1.87\n",
            "[1460 | 2685.36] loss=1.58 avg=1.86\n",
            "[1470 | 2702.65] loss=2.11 avg=1.87\n",
            "[1480 | 2719.92] loss=1.32 avg=1.86\n",
            "[1490 | 2737.13] loss=1.70 avg=1.86\n",
            "[1500 | 2754.37] loss=0.69 avg=1.84\n",
            "Saving checkpoint/KNGPT2P/model-1500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='KNGPT2P')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cyxKd3sGdTW"
      },
      "source": [
        "import pandas as pd\n",
        "import pylab as plt\n",
        "\n",
        "# Create dataframe\n",
        "file_name = \"training.log\"\n",
        "df = pd.DataFrame.from_csv(file_name)\n",
        "df.plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xApgn79iGb3Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DCcx5u7sbPTD"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='KNGPT2P')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='KNGPT2P')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL"
      },
      "source": [
        "gpt2.generate(sess, run_name='KNGPT2P')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejGAdN9ZL3LJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7856ba23-125e-43cb-f597-04f46da8b40e"
      },
      "source": [
        "gpt2.generate(sess, \n",
        "              run_name='KNGPT2P',\n",
        "              length=15,\n",
        "              temperature=0.9,\n",
        "              prefix=\"asho\",\n",
        "              nsamples=4,\n",
        "              batch_size=4,\n",
        "              top_p=0.95,\n",
        "              top_k=40,\n",
        "              truncate='<|eos|>',\n",
        "              return_as_list=False,\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "asho wotta kaalli kaalloon aafoona ittoshi g\n",
            "====================\n",
            "asho ebi bullin bi doyito gaata, ebiyoo \n",
            "====================\n",
            "asho,\n",
            "====================\n",
            "asho bo cookeebeet bireena' oochee ikk\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "kFsx6cC4L5Hx",
        "outputId": "50b10e76-2709-464d-b340-4b347be446c1"
      },
      "source": [
        "tag_start='<|sos|>'\n",
        "while True:\n",
        "  print('Input kafi-noonoo text or exit or \"Enter\" key for unconditional sampling.....')\n",
        "  prefix1 = input(\">>> \")\n",
        "  if prefix1 == 'exit':\n",
        "    break\n",
        "  if prefix1 == '':\n",
        "    prefix1 = tag_start \n",
        "  sequences = gpt2.generate(sess, \n",
        "              run_name='KNGPT2P',\n",
        "              length=15,\n",
        "              temperature=0.9,\n",
        "              prefix=prefix1,\n",
        "              nsamples=4,\n",
        "              batch_size=4,\n",
        "              top_p=0.95,\n",
        "              top_k=40,\n",
        "              truncate='<|eos|>',\n",
        "              return_as_list=False,)\n",
        "  #for sequence in enumerate(sequences):\n",
        "  #print('\\n====== GENERATION {} ======')\n",
        "  print(sequences)\n",
        "     #generate_samples(args, model, PROMPT)\n",
        "  print('\\n--------------------------------------------')\n",
        "print('Thank you.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input kafi-noonoo text or exit or \"Enter\" key for unconditional sampling.....\n",
            ">>> asho\n",
            "asho- neexaqqi, yeerin gallatabote! i\n",
            "====================\n",
            "asho shemmo qaaweet degoon immo hallimmon\n",
            "====================\n",
            "asho bi tunetochiye; tunatee gaawatone eb\n",
            "====================\n",
            "asho,\n",
            "====================\n",
            "None\n",
            "\n",
            "--------------------------------------------\n",
            "Input kafi-noonoo text or exit or \"Enter\" key for unconditional sampling.....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \"\"\"\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-6d8709b8926d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input kafi-noonoo text or exit or \"Enter\" key for unconditional sampling.....'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mprefix1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">>> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mprefix1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6p6arifSL0"
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      run_name='/content/drive/MyDrive/finetuned_models/checkpoint/KNGPT2P',\n",
        "                      destination_path=gen_file,\n",
        "                      length=500,\n",
        "                      temperature=0.9,\n",
        "                      nsamples=100,\n",
        "                      batch_size=2,\n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LRex8lfv1g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da5e0e36-b0c7-42fa-c8d2-1d16c8fab2a0"
      },
      "source": [
        "# may have to run twice to get file to download\n",
        "files.download(gen_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6cd934c5-5bab-46d3-a186-8e101a0e7adf\", \"gpt2_gentext_20201207_182314.txt\", 112463)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQAN3M6RT7Kj"
      },
      "source": [
        "## Generate Text From The Pretrained Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsUd_jHgUZnD"
      },
      "source": [
        "model_name = \"774M\"\n",
        "\n",
        "gpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAe4NpKNUj2C"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.load_gpt2(sess, model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xInIZKaU104"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              model_name=model_name,\n",
        "              prefix=\"The secret of life is\",\n",
        "              length=100,\n",
        "              temperature=0.7,\n",
        "              top_p=0.9,\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX"
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}